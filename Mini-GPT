{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahanvi513/Mini-GPT/blob/main/Mini-GPT\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ78UWAiHlr1",
        "outputId": "f89cc334-97fa-442b-c344-7d6be4427ecc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "g-3QBhLyYwb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUelU1WSwqen",
        "outputId": "12c4189e-048d-4aa8-8473-83ed16114601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZijlFjlCFFM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=10, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    GPT_CONFIG_124M = {\n",
        "        \"vocab_size\": 50257,     # Vocabulary size\n",
        "        \"context_length\": 256,  # Context length\n",
        "        \"emb_dim\": 768,          # Embedding dimension\n",
        "        \"n_heads\": 12,           # Number of attention heads\n",
        "        \"n_layers\": 12,          # Number of layers\n",
        "        \"drop_rate\": 0.1,        # Dropout rate\n",
        "        \"qkv_bias\": False        # Query-Key-Value bias\n",
        "    }\n",
        "\n",
        "    torch.manual_seed(123)\n",
        "    model = GPTModel(GPT_CONFIG_124M)\n",
        "    model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"eBook-Pride-and-Prejudice.txt\"\n",
        "url = \"https://raw.githubusercontent.com/jahanvi513/Pytorch/main/Project/eBook-Pride-and-Prejudice\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data = response.read().decode('utf-8')\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()\n",
        "print(\"Total number of characters:\", len(text_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50-p5lBpSRSr",
        "outputId": "dc28f61e-c6a8-4d13-f40b-5e548d4eec70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 748124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ],
      "metadata": {
        "id": "QNYCrXpFXfM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "\n",
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=10,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride= GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=10,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "Adc3QTukXnps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Qu0n7lXxX3XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "xhdH9a7qX5Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "p24zDDCKX7kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)"
      ],
      "metadata": {
        "id": "jub1qGBFYDh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Till this moment I never knew myself.\", tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ht4zkQ_YMaM",
        "outputId": "9e35c266-b12c-4e57-c2ed-76e2094aa381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 10.645, Val loss 10.640\n",
            "Ep 1 (Step 000005): Train loss 9.350, Val loss 9.413\n",
            "Ep 1 (Step 000010): Train loss 8.547, Val loss 9.004\n",
            "Ep 1 (Step 000015): Train loss 8.678, Val loss 8.703\n",
            "Ep 1 (Step 000020): Train loss 8.034, Val loss 8.430\n",
            "Ep 1 (Step 000025): Train loss 7.772, Val loss 8.175\n",
            "Ep 1 (Step 000030): Train loss 7.860, Val loss 7.928\n",
            "Ep 1 (Step 000035): Train loss 7.534, Val loss 7.695\n",
            "Ep 1 (Step 000040): Train loss 7.393, Val loss 7.467\n",
            "Ep 1 (Step 000045): Train loss 7.028, Val loss 7.248\n",
            "Ep 1 (Step 000050): Train loss 6.954, Val loss 7.053\n",
            "Ep 1 (Step 000055): Train loss 6.592, Val loss 6.888\n",
            "Ep 1 (Step 000060): Train loss 6.592, Val loss 6.740\n",
            "Ep 1 (Step 000065): Train loss 6.449, Val loss 6.612\n",
            "Till this moment I never knew myself.   ”  ” “ “, and ” “, and “ “, and “, and “ “, and “,\n",
            "Ep 2 (Step 000070): Train loss 6.394, Val loss 6.495\n",
            "Ep 2 (Step 000075): Train loss 6.095, Val loss 6.395\n",
            "Ep 2 (Step 000080): Train loss 6.050, Val loss 6.312\n",
            "Ep 2 (Step 000085): Train loss 6.079, Val loss 6.235\n",
            "Ep 2 (Step 000090): Train loss 5.955, Val loss 6.168\n",
            "Ep 2 (Step 000095): Train loss 5.858, Val loss 6.105\n",
            "Ep 2 (Step 000100): Train loss 5.879, Val loss 6.053\n",
            "Ep 2 (Step 000105): Train loss 5.717, Val loss 6.009\n",
            "Ep 2 (Step 000110): Train loss 5.446, Val loss 5.965\n",
            "Ep 2 (Step 000115): Train loss 5.727, Val loss 5.926\n",
            "Ep 2 (Step 000120): Train loss 5.650, Val loss 5.892\n",
            "Ep 2 (Step 000125): Train loss 5.684, Val loss 5.852\n",
            "Ep 2 (Step 000130): Train loss 5.697, Val loss 5.817\n",
            "Ep 2 (Step 000135): Train loss 5.674, Val loss 5.788\n",
            "Till this moment I never knew myself.   ” “I.” ” “I,“I,” “I, and,” “I,” ” ” �\n",
            "Ep 3 (Step 000140): Train loss 5.411, Val loss 5.759\n",
            "Ep 3 (Step 000145): Train loss 5.660, Val loss 5.732\n",
            "Ep 3 (Step 000150): Train loss 5.426, Val loss 5.710\n",
            "Ep 3 (Step 000155): Train loss 5.593, Val loss 5.687\n",
            "Ep 3 (Step 000160): Train loss 5.495, Val loss 5.664\n",
            "Ep 3 (Step 000165): Train loss 5.490, Val loss 5.641\n",
            "Ep 3 (Step 000170): Train loss 5.389, Val loss 5.619\n",
            "Ep 3 (Step 000175): Train loss 5.269, Val loss 5.598\n",
            "Ep 3 (Step 000180): Train loss 5.243, Val loss 5.569\n",
            "Ep 3 (Step 000185): Train loss 5.326, Val loss 5.555\n",
            "Ep 3 (Step 000190): Train loss 5.259, Val loss 5.534\n",
            "Ep 3 (Step 000195): Train loss 5.281, Val loss 5.518\n",
            "Ep 3 (Step 000200): Train loss 5.273, Val loss 5.498\n",
            "Ep 3 (Step 000205): Train loss 5.242, Val loss 5.476\n",
            "Till this moment I never knew myself.  ” ” “I have been.” “I am not be  “I have been to be in the ” “I have been.“I have been.\n",
            "Ep 4 (Step 000210): Train loss 5.259, Val loss 5.463\n",
            "Ep 4 (Step 000215): Train loss 5.231, Val loss 5.450\n",
            "Ep 4 (Step 000220): Train loss 5.301, Val loss 5.428\n",
            "Ep 4 (Step 000225): Train loss 5.059, Val loss 5.415\n",
            "Ep 4 (Step 000230): Train loss 5.156, Val loss 5.398\n",
            "Ep 4 (Step 000235): Train loss 5.095, Val loss 5.387\n",
            "Ep 4 (Step 000240): Train loss 5.088, Val loss 5.362\n",
            "Ep 4 (Step 000245): Train loss 5.263, Val loss 5.348\n",
            "Ep 4 (Step 000250): Train loss 4.951, Val loss 5.338\n",
            "Ep 4 (Step 000255): Train loss 5.036, Val loss 5.323\n",
            "Ep 4 (Step 000260): Train loss 4.895, Val loss 5.309\n",
            "Ep 4 (Step 000265): Train loss 4.928, Val loss 5.301\n",
            "Ep 4 (Step 000270): Train loss 4.940, Val loss 5.282\n",
            "Ep 4 (Step 000275): Train loss 5.058, Val loss 5.269\n",
            "Till this moment I never knew myself.  “I am not be a very much to be so much to be so much.” “I am not be a   “I am sure,“I am not be so,” said\n",
            "Ep 5 (Step 000280): Train loss 5.057, Val loss 5.259\n",
            "Ep 5 (Step 000285): Train loss 4.708, Val loss 5.252\n",
            "Ep 5 (Step 000290): Train loss 5.021, Val loss 5.240\n",
            "Ep 5 (Step 000295): Train loss 4.933, Val loss 5.233\n",
            "Ep 5 (Step 000300): Train loss 4.707, Val loss 5.216\n",
            "Ep 5 (Step 000305): Train loss 4.686, Val loss 5.210\n",
            "Ep 5 (Step 000310): Train loss 4.947, Val loss 5.200\n",
            "Ep 5 (Step 000315): Train loss 4.746, Val loss 5.187\n",
            "Ep 5 (Step 000320): Train loss 4.807, Val loss 5.175\n",
            "Ep 5 (Step 000325): Train loss 4.870, Val loss 5.173\n",
            "Ep 5 (Step 000330): Train loss 4.877, Val loss 5.153\n",
            "Ep 5 (Step 000335): Train loss 4.834, Val loss 5.142\n",
            "Ep 5 (Step 000340): Train loss 4.948, Val loss 5.143\n",
            "Till this moment I never knew myself. “I am sure, I am sure I am not be ” “I am sure,” “I am sure, I am sure, I am sure I am sure you will be ” \n",
            "Ep 6 (Step 000345): Train loss 4.659, Val loss 5.131\n",
            "Ep 6 (Step 000350): Train loss 4.741, Val loss 5.115\n",
            "Ep 6 (Step 000355): Train loss 4.806, Val loss 5.109\n",
            "Ep 6 (Step 000360): Train loss 4.841, Val loss 5.104\n",
            "Ep 6 (Step 000365): Train loss 4.634, Val loss 5.100\n",
            "Ep 6 (Step 000370): Train loss 4.336, Val loss 5.086\n",
            "Ep 6 (Step 000375): Train loss 4.538, Val loss 5.083\n",
            "Ep 6 (Step 000380): Train loss 4.646, Val loss 5.077\n",
            "Ep 6 (Step 000385): Train loss 4.685, Val loss 5.081\n",
            "Ep 6 (Step 000390): Train loss 4.517, Val loss 5.066\n",
            "Ep 6 (Step 000395): Train loss 4.385, Val loss 5.059\n",
            "Ep 6 (Step 000400): Train loss 4.615, Val loss 5.052\n",
            "Ep 6 (Step 000405): Train loss 4.656, Val loss 5.047\n",
            "Ep 6 (Step 000410): Train loss 4.371, Val loss 5.031\n",
            "Till this moment I never knew myself.”  “I am not be so much to be so much to be  “I am sure you.“I am not be a very ” said she is not be “I am sure you\n",
            "Ep 7 (Step 000415): Train loss 4.648, Val loss 5.024\n",
            "Ep 7 (Step 000420): Train loss 4.270, Val loss 5.021\n",
            "Ep 7 (Step 000425): Train loss 4.595, Val loss 5.020\n",
            "Ep 7 (Step 000430): Train loss 4.563, Val loss 5.006\n",
            "Ep 7 (Step 000435): Train loss 4.530, Val loss 4.999\n",
            "Ep 7 (Step 000440): Train loss 4.544, Val loss 4.992\n",
            "Ep 7 (Step 000445): Train loss 4.491, Val loss 4.993\n",
            "Ep 7 (Step 000450): Train loss 4.378, Val loss 4.990\n",
            "Ep 7 (Step 000455): Train loss 4.195, Val loss 4.982\n",
            "Ep 7 (Step 000460): Train loss 4.503, Val loss 4.976\n",
            "Ep 7 (Step 000465): Train loss 4.410, Val loss 4.970\n",
            "Ep 7 (Step 000470): Train loss 4.281, Val loss 4.963\n",
            "Ep 7 (Step 000475): Train loss 4.333, Val loss 4.958\n",
            "Ep 7 (Step 000480): Train loss 4.429, Val loss 4.953\n",
            "Till this moment I never knew myself.”  “I am not be so much to be “I amiable.” ” “I am not be a very much to be “I am not be so much as you have\n",
            "Ep 8 (Step 000485): Train loss 4.275, Val loss 4.951\n",
            "Ep 8 (Step 000490): Train loss 4.303, Val loss 4.936\n",
            "Ep 8 (Step 000495): Train loss 4.379, Val loss 4.942\n",
            "Ep 8 (Step 000500): Train loss 4.175, Val loss 4.935\n",
            "Ep 8 (Step 000505): Train loss 4.460, Val loss 4.935\n",
            "Ep 8 (Step 000510): Train loss 4.375, Val loss 4.926\n",
            "Ep 8 (Step 000515): Train loss 4.325, Val loss 4.917\n",
            "Ep 8 (Step 000520): Train loss 4.299, Val loss 4.922\n",
            "Ep 8 (Step 000525): Train loss 4.120, Val loss 4.913\n",
            "Ep 8 (Step 000530): Train loss 4.207, Val loss 4.907\n",
            "Ep 8 (Step 000535): Train loss 4.293, Val loss 4.899\n",
            "Ep 8 (Step 000540): Train loss 4.122, Val loss 4.907\n",
            "Ep 8 (Step 000545): Train loss 4.304, Val loss 4.901\n",
            "Ep 8 (Step 000550): Train loss 4.298, Val loss 4.893\n",
            "Till this moment I never knew myself.”  “I am sure you are not be so much “I am sure,” ” said Elizabeth, “I do not be “I do not be “I am sure,\n",
            "Ep 9 (Step 000555): Train loss 4.247, Val loss 4.886\n",
            "Ep 9 (Step 000560): Train loss 4.212, Val loss 4.894\n",
            "Ep 9 (Step 000565): Train loss 4.367, Val loss 4.899\n",
            "Ep 9 (Step 000570): Train loss 4.316, Val loss 4.887\n",
            "Ep 9 (Step 000575): Train loss 4.095, Val loss 4.893\n",
            "Ep 9 (Step 000580): Train loss 4.439, Val loss 4.895\n",
            "Ep 9 (Step 000585): Train loss 4.270, Val loss 4.876\n",
            "Ep 9 (Step 000590): Train loss 4.222, Val loss 4.875\n",
            "Ep 9 (Step 000595): Train loss 4.172, Val loss 4.875\n",
            "Ep 9 (Step 000600): Train loss 4.237, Val loss 4.870\n",
            "Ep 9 (Step 000605): Train loss 4.114, Val loss 4.854\n",
            "Ep 9 (Step 000610): Train loss 4.185, Val loss 4.859\n",
            "Ep 9 (Step 000615): Train loss 4.074, Val loss 4.846\n",
            "Ep 9 (Step 000620): Train loss 4.144, Val loss 4.838\n",
            "Till this moment I never knew myself.”  “I am sure you will not be so.” ”  “I am sure you will not be so much to be in the “I am sure you know,” �\n",
            "Ep 10 (Step 000625): Train loss 4.167, Val loss 4.841\n",
            "Ep 10 (Step 000630): Train loss 4.138, Val loss 4.846\n",
            "Ep 10 (Step 000635): Train loss 4.255, Val loss 4.850\n",
            "Ep 10 (Step 000640): Train loss 4.026, Val loss 4.841\n",
            "Ep 10 (Step 000645): Train loss 4.112, Val loss 4.834\n",
            "Ep 10 (Step 000650): Train loss 4.144, Val loss 4.832\n",
            "Ep 10 (Step 000655): Train loss 3.931, Val loss 4.844\n",
            "Ep 10 (Step 000660): Train loss 3.939, Val loss 4.843\n",
            "Ep 10 (Step 000665): Train loss 3.859, Val loss 4.826\n",
            "Ep 10 (Step 000670): Train loss 3.920, Val loss 4.827\n",
            "Ep 10 (Step 000675): Train loss 4.144, Val loss 4.826\n",
            "Ep 10 (Step 000680): Train loss 3.890, Val loss 4.825\n",
            "Ep 10 (Step 000685): Train loss 3.985, Val loss 4.819\n",
            "Till this moment I never knew myself.”  “I am not to be so,” said Elizabeth,”  “I am sure I do not be so much to be in the ” said Elizabeth, “I am sure, I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"gpt2_model.pth\")"
      ],
      "metadata": {
        "id": "dWAopqZ-0E9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to fetch the trained model from Google Drive and generate text"
      ],
      "metadata": {
        "id": "EpjLlpIk84t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown\n",
        "!gdown --id 1zwHb869GtLypwjD11gxjbWFgqlap97Wg -O gpt_model.pth\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "        \"vocab_size\": 50257,     # Vocabulary size\n",
        "        \"context_length\": 256,  # Context length\n",
        "        \"emb_dim\": 768,          # Embedding dimension\n",
        "        \"n_heads\": 12,           # Number of attention heads\n",
        "        \"n_layers\": 12,          # Number of layers\n",
        "        \"drop_rate\": 0.1,        # Dropout rate\n",
        "        \"qkv_bias\": False        # Query-Key-Value bias\n",
        "    }\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model.load_state_dict(torch.load(\"gpt2_model.pth\", map_location=torch.device('cuda')))\n",
        "model.eval()\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Till this moment I never knew myself.\", tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXRybgqQ6fcL",
        "outputId": "0b69ed0b-409c-4b42-af29-7d6f0101e887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1zwHb869GtLypwjD11gxjbWFgqlap97Wg\n",
            "From (redirected): https://drive.google.com/uc?id=1zwHb869GtLypwjD11gxjbWFgqlap97Wg&confirm=t&uuid=7e8ed6dd-c645-4f66-ab55-7aa6119a620d\n",
            "To: /content/gpt_model.pth\n",
            "100% 653M/653M [00:07<00:00, 91.6MB/s]\n",
            "Ep 1 (Step 000000): Train loss 4.058, Val loss 4.811\n",
            "Ep 1 (Step 000005): Train loss 4.017, Val loss 4.831\n",
            "Ep 1 (Step 000010): Train loss 3.876, Val loss 4.816\n",
            "Ep 1 (Step 000015): Train loss 3.958, Val loss 4.808\n",
            "Ep 1 (Step 000020): Train loss 4.046, Val loss 4.827\n",
            "Ep 1 (Step 000025): Train loss 3.995, Val loss 4.810\n",
            "Ep 1 (Step 000030): Train loss 3.806, Val loss 4.802\n",
            "Ep 1 (Step 000035): Train loss 3.841, Val loss 4.824\n",
            "Ep 1 (Step 000040): Train loss 3.839, Val loss 4.800\n",
            "Ep 1 (Step 000045): Train loss 3.751, Val loss 4.808\n",
            "Ep 1 (Step 000050): Train loss 3.741, Val loss 4.809\n",
            "Ep 1 (Step 000055): Train loss 3.849, Val loss 4.824\n",
            "Ep 1 (Step 000060): Train loss 3.709, Val loss 4.800\n",
            "Ep 1 (Step 000065): Train loss 3.778, Val loss 4.797\n",
            "Till this moment I never knew myself.”  “I am not be so much as you will be ” said Elizabeth,”  “I am sure you have been.” said Elizabeth, “I am sure, “I have\n",
            "Ep 2 (Step 000070): Train loss 3.701, Val loss 4.789\n",
            "Ep 2 (Step 000075): Train loss 3.839, Val loss 4.800\n",
            "Ep 2 (Step 000080): Train loss 3.784, Val loss 4.797\n",
            "Ep 2 (Step 000085): Train loss 3.851, Val loss 4.816\n",
            "Ep 2 (Step 000090): Train loss 3.782, Val loss 4.789\n",
            "Ep 2 (Step 000095): Train loss 3.791, Val loss 4.797\n",
            "Ep 2 (Step 000100): Train loss 3.797, Val loss 4.788\n",
            "Ep 2 (Step 000105): Train loss 3.825, Val loss 4.799\n",
            "Ep 2 (Step 000110): Train loss 3.750, Val loss 4.797\n",
            "Ep 2 (Step 000115): Train loss 3.679, Val loss 4.788\n",
            "Ep 2 (Step 000120): Train loss 3.647, Val loss 4.780\n",
            "Ep 2 (Step 000125): Train loss 3.632, Val loss 4.803\n",
            "Ep 2 (Step 000130): Train loss 3.610, Val loss 4.772\n",
            "Ep 2 (Step 000135): Train loss 3.798, Val loss 4.777\n",
            "Till this moment I never knew myself.”  “I have not be so much as you,” “I have no more than you know, I have been so much ”  “I am sure you know,” said Elizabeth\n",
            "Ep 3 (Step 000140): Train loss 3.823, Val loss 4.784\n",
            "Ep 3 (Step 000145): Train loss 3.620, Val loss 4.788\n",
            "Ep 3 (Step 000150): Train loss 3.753, Val loss 4.797\n",
            "Ep 3 (Step 000155): Train loss 3.516, Val loss 4.793\n",
            "Ep 3 (Step 000160): Train loss 3.626, Val loss 4.795\n",
            "Ep 3 (Step 000165): Train loss 3.483, Val loss 4.785\n",
            "Ep 3 (Step 000170): Train loss 3.585, Val loss 4.783\n",
            "Ep 3 (Step 000175): Train loss 3.572, Val loss 4.794\n",
            "Ep 3 (Step 000180): Train loss 3.738, Val loss 4.789\n",
            "Ep 3 (Step 000185): Train loss 3.685, Val loss 4.782\n",
            "Ep 3 (Step 000190): Train loss 3.597, Val loss 4.789\n",
            "Ep 3 (Step 000195): Train loss 3.577, Val loss 4.780\n",
            "Ep 3 (Step 000200): Train loss 3.645, Val loss 4.774\n",
            "Ep 3 (Step 000205): Train loss 3.569, Val loss 4.793\n",
            "Till this moment I never knew myself.”  “I have not be so much to me.” “I have not know you are not be ” “I have no more.” ”  “I have\n",
            "Ep 4 (Step 000210): Train loss 3.503, Val loss 4.778\n",
            "Ep 4 (Step 000215): Train loss 3.486, Val loss 4.776\n",
            "Ep 4 (Step 000220): Train loss 3.408, Val loss 4.792\n",
            "Ep 4 (Step 000225): Train loss 3.519, Val loss 4.774\n",
            "Ep 4 (Step 000230): Train loss 3.340, Val loss 4.795\n",
            "Ep 4 (Step 000235): Train loss 3.537, Val loss 4.800\n",
            "Ep 4 (Step 000240): Train loss 3.461, Val loss 4.810\n",
            "Ep 4 (Step 000245): Train loss 3.444, Val loss 4.798\n",
            "Ep 4 (Step 000250): Train loss 3.424, Val loss 4.785\n",
            "Ep 4 (Step 000255): Train loss 3.441, Val loss 4.806\n",
            "Ep 4 (Step 000260): Train loss 3.562, Val loss 4.771\n",
            "Ep 4 (Step 000265): Train loss 3.332, Val loss 4.780\n",
            "Ep 4 (Step 000270): Train loss 3.488, Val loss 4.794\n",
            "Ep 4 (Step 000275): Train loss 3.473, Val loss 4.796\n",
            "Till this moment I never knew myself.”  “I am not be so much to me,” said Elizabeth, “I am that, I have been so much to be in the same that you.”  “I am sure\n",
            "Ep 5 (Step 000280): Train loss 3.381, Val loss 4.810\n",
            "Ep 5 (Step 000285): Train loss 3.364, Val loss 4.806\n",
            "Ep 5 (Step 000290): Train loss 3.290, Val loss 4.822\n",
            "Ep 5 (Step 000295): Train loss 3.548, Val loss 4.813\n",
            "Ep 5 (Step 000300): Train loss 3.369, Val loss 4.819\n",
            "Ep 5 (Step 000305): Train loss 3.409, Val loss 4.810\n",
            "Ep 5 (Step 000310): Train loss 3.395, Val loss 4.818\n",
            "Ep 5 (Step 000315): Train loss 3.316, Val loss 4.817\n",
            "Ep 5 (Step 000320): Train loss 3.256, Val loss 4.795\n",
            "Ep 5 (Step 000325): Train loss 3.408, Val loss 4.799\n",
            "Ep 5 (Step 000330): Train loss 3.297, Val loss 4.803\n",
            "Ep 5 (Step 000335): Train loss 3.223, Val loss 4.783\n",
            "Ep 5 (Step 000340): Train loss 3.190, Val loss 4.798\n",
            "Till this moment I never knew myself.”  “I am not be so much to me,” said “I am sure I am sure you think it is not to be of your own family.”  “I am sure you\n",
            "Ep 6 (Step 000345): Train loss 3.347, Val loss 4.806\n",
            "Ep 6 (Step 000350): Train loss 3.291, Val loss 4.807\n",
            "Ep 6 (Step 000355): Train loss 3.187, Val loss 4.832\n",
            "Ep 6 (Step 000360): Train loss 3.157, Val loss 4.833\n",
            "Ep 6 (Step 000365): Train loss 3.323, Val loss 4.827\n",
            "Ep 6 (Step 000370): Train loss 3.199, Val loss 4.821\n",
            "Ep 6 (Step 000375): Train loss 3.275, Val loss 4.820\n",
            "Ep 6 (Step 000380): Train loss 3.161, Val loss 4.831\n",
            "Ep 6 (Step 000385): Train loss 3.262, Val loss 4.817\n",
            "Ep 6 (Step 000390): Train loss 3.305, Val loss 4.865\n",
            "Ep 6 (Step 000395): Train loss 3.302, Val loss 4.835\n",
            "Ep 6 (Step 000400): Train loss 3.272, Val loss 4.830\n",
            "Ep 6 (Step 000405): Train loss 3.167, Val loss 4.804\n",
            "Ep 6 (Step 000410): Train loss 3.161, Val loss 4.829\n",
            "Till this moment I never knew myself.”  “I am not be so much to me,” said ” said Elizabeth, “I am not know that you have been.”  “I have not.” said Elizabeth,\n",
            "Ep 7 (Step 000415): Train loss 3.194, Val loss 4.833\n",
            "Ep 7 (Step 000420): Train loss 3.103, Val loss 4.840\n",
            "Ep 7 (Step 000425): Train loss 3.094, Val loss 4.823\n",
            "Ep 7 (Step 000430): Train loss 3.201, Val loss 4.842\n",
            "Ep 7 (Step 000435): Train loss 3.122, Val loss 4.843\n",
            "Ep 7 (Step 000440): Train loss 3.069, Val loss 4.845\n",
            "Ep 7 (Step 000445): Train loss 3.177, Val loss 4.856\n",
            "Ep 7 (Step 000450): Train loss 3.174, Val loss 4.844\n",
            "Ep 7 (Step 000455): Train loss 3.114, Val loss 4.859\n",
            "Ep 7 (Step 000460): Train loss 3.116, Val loss 4.865\n",
            "Ep 7 (Step 000465): Train loss 3.138, Val loss 4.853\n",
            "Ep 7 (Step 000470): Train loss 3.057, Val loss 4.862\n",
            "Ep 7 (Step 000475): Train loss 3.108, Val loss 4.858\n",
            "Ep 7 (Step 000480): Train loss 2.981, Val loss 4.863\n",
            "Till this moment I never knew myself.”  “I am not be the same time of my dear,” said she the whole party, “I am sure I have not to be so much that you at the same time, I am sure you\n",
            "Ep 8 (Step 000485): Train loss 3.120, Val loss 4.851\n",
            "Ep 8 (Step 000490): Train loss 3.029, Val loss 4.844\n",
            "Ep 8 (Step 000495): Train loss 3.149, Val loss 4.876\n",
            "Ep 8 (Step 000500): Train loss 3.080, Val loss 4.871\n",
            "Ep 8 (Step 000505): Train loss 3.022, Val loss 4.873\n",
            "Ep 8 (Step 000510): Train loss 3.090, Val loss 4.884\n",
            "Ep 8 (Step 000515): Train loss 3.081, Val loss 4.899\n",
            "Ep 8 (Step 000520): Train loss 3.019, Val loss 4.892\n",
            "Ep 8 (Step 000525): Train loss 2.999, Val loss 4.879\n",
            "Ep 8 (Step 000530): Train loss 2.972, Val loss 4.901\n",
            "Ep 8 (Step 000535): Train loss 3.085, Val loss 4.885\n",
            "Ep 8 (Step 000540): Train loss 3.078, Val loss 4.884\n",
            "Ep 8 (Step 000545): Train loss 2.893, Val loss 4.888\n",
            "Ep 8 (Step 000550): Train loss 2.913, Val loss 4.910\n",
            "Till this moment I never knew myself.”  “I am not be the same time of the same time of the the whole of the whole party,” said Elizabeth, “I am sure, and in-room, and I am sure I have\n",
            "Ep 9 (Step 000555): Train loss 2.994, Val loss 4.893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "Op9B42meYOpp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "4b4080cd-9ab7-45e3-b2b8-c8d052fd30c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Project Report](https://docs.google.com/document/d/1UqfgtdQqA9AewWvyHaNXvG0HvkHNGtRCjWaOyI6fWJ8/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "RgPq3Zsax4Az"
      }
    }
  ]
}